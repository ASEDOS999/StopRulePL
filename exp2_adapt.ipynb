{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Experiments 2.2. Quadratic Programming and Adaptive GD\n",
    "\n",
    "Minimization of function\n",
    "\n",
    "$$f(x)=\\sum\\limits_{i=k}^N d_i x_i^2$$\n",
    "for positive $d_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.config import config\n",
    "import timeit\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import gradf_inexact\n",
    "from methods import GradientDescent, parse_logs, AdaptiveL, StepSize, AdaptiveNoiseGD\n",
    "from methods import ConstantStepSize, AdaptiveLdelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')\n",
    "params = {'legend.fontsize': 20,\n",
    "          'legend.handlelength': 4,\n",
    "          \"axes.labelsize\": 45,\n",
    "          \"xtick.labelsize\": 25,\n",
    "          \"ytick.labelsize\": 25,\n",
    "          \"lines.linewidth\": 2,\n",
    "           \"axes.titlesize\":30}\n",
    "matplotlib.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pics = \"../pics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x, A):\n",
    "    m = A.shape[0]\n",
    "    r = A@x\n",
    "    return 1/2 * x.T @ A @ x\n",
    "\n",
    "gradf = jax.grad(f1, argnums=0, has_aux=False)\n",
    "jit_gradf = jax.jit(gradf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Comparison of Theoretical Iterations Count and Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "n = 100\n",
    "k = 10\n",
    "mu = 0.1\n",
    "d = np.zeros(n)\n",
    "d[:k] *= 0\n",
    "d[k:] = np.linspace(mu, 1, n-k)\n",
    "A = np.diag(d)\n",
    "w = np.random.randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals, _ = np.linalg.eigh(A)\n",
    "eigvals.sort()\n",
    "L = np.real(eigvals.max())\n",
    "mu = eigvals[eigvals>=1e-12].min()\n",
    "L, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma=0\n",
    "gradf = lambda x: np.array(jit_gradf(x, A).block_until_ready())\n",
    "f = lambda x: f1(x, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.randn(n)\n",
    "f(np.zeros(A.shape[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The case when $\\xi \\sim \\mathcal{U}(S_1(0))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 948.6832980505138\n",
      "\t1e-07\t668\t243.45\t948.683296\t2.09\n",
      "\t1e-07\t552\t291.62\t948.683297\t1.14\n",
      "\t1e-07\t1525\t139.02\t948.683296\t2.29\n",
      "\n",
      "\t0.0001\t421\t151.83\t948.681145\t2.33\n",
      "\t0.0001\t347\t190.01\t948.682281\t1.63\n",
      "\t0.0001\t837\t76.72\t948.680963\t2.31\n",
      "\n",
      "\t0.1\t75\t24.67\t946.713095\t1.97\n",
      "\t0.1\t162\t87.82\t947.630876\t1.14\n",
      "\t0.1\t158\t14.88\t946.296396\t2.29\n",
      "\n",
      "0.1 948.6832980505138\n",
      "\t1e-07\t72\t26.40\t948.683298\t1.99\n",
      "\t1e-07\t109\t56.88\t948.683298\t0.83\n",
      "\t1e-07\t169\t15.84\t948.683298\t2.22\n",
      "\n",
      "\t0.0001\t46\t16.39\t948.683036\t2.16\n",
      "\t0.0001\t80\t43.50\t948.683189\t0.84\n",
      "\t0.0001\t104\t10.00\t948.683009\t2.14\n",
      "\n",
      "\t0.1\t19\t6.62\t948.400252\t2.27\n",
      "\t0.1\t48\t31.55\t948.521819\t0.89\n",
      "\t0.1\t42\t4.40\t948.318625\t1.94\n",
      "\n",
      "0.9 948.6832980505138\n",
      "\t1e-07\t10\t3.44\t948.683298\t2.15\n",
      "\t1e-07\t59\t30.40\t948.683298\t0.73\n",
      "\t1e-07\t11\t1.56\t948.683298\t0.90\n",
      "\n",
      "\t0.0001\t8\t2.73\t948.683265\t0.98\n",
      "\t0.0001\t47\t25.43\t948.683237\t0.70\n",
      "\t0.0001\t8\t1.26\t948.683291\t0.94\n",
      "\n",
      "\t0.1\t5\t1.65\t948.649800\t0.95\n",
      "\t0.1\t37\t20.50\t948.611802\t0.74\n",
      "\t0.1\t5\t0.88\t948.673749\t0.92\n",
      "\n",
      "0.99 948.6832980505138\n",
      "\t1e-07\t6\t2.16\t948.683298\t1.03\n",
      "\t1e-07\t50\t29.78\t948.683298\t0.72\n",
      "\t1e-07\t6\t1.01\t948.683298\t0.98\n",
      "\n",
      "\t0.0001\t5\t1.75\t948.683181\t1.95\n",
      "\t0.0001\t46\t27.37\t948.683228\t0.74\n",
      "\t0.0001\t5\t0.92\t948.683284\t0.97\n",
      "\n",
      "\t0.1\t3\t1.12\t948.651973\t1.04\n",
      "\t0.1\t36\t25.36\t948.617911\t0.70\n",
      "\t0.1\t3\t0.55\t948.656103\t1.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "np.random.seed(1)\n",
    "n = 100\n",
    "k = 10\n",
    "mu_list = [0.01, 0.1, 0.9, 0.99]\n",
    "res = {mu:{\"delta\":[], \n",
    "           \"iters_adaptL\":[], \"time_adaptL\":[], \"adaptL,x0-x*\": [], \"normg_adaptL\": [],\n",
    "           \"iters_exact\":[], \"time_exact\":[], \"exact,x0-x*\": [], \"normg_exact\": [],\n",
    "          \"iters_adaptLdelta\":[], \"time_adaptLdelta\":[], \"adaptLdelta,x0-x*\": [], \"normg_adaptLdelta\": []} for mu in mu_list}\n",
    "dist = {}\n",
    "number = 200\n",
    "\n",
    "for mu in mu_list:\n",
    "    d = np.zeros(n)\n",
    "    d[:k] *= 0\n",
    "    d[k:] = np.linspace(mu, 1, n-k)\n",
    "    A = np.diag(d)\n",
    "    w = np.random.randn(n)\n",
    "    sigma=0\n",
    "    eigvals, _ = np.linalg.eigh(A)\n",
    "    eigvals.sort()\n",
    "    L = np.real(eigvals.max())\n",
    "    mu = eigvals[eigvals>=1e-12].min()\n",
    "    L, mu\n",
    "    gradf = lambda x: np.array(jit_gradf(x, A).block_until_ready())\n",
    "    f = lambda x: f1(x, A)\n",
    "    f(np.zeros(A.shape[-1]))\n",
    "    alpha = 1/L\n",
    "    w = np.ones(n)*100\n",
    "    wsol = np.where(d!=0, 0, w)\n",
    "    dist[mu] = np.linalg.norm(w-wsol)\n",
    "    v = np.random.randn(*w.shape)\n",
    "    v = np.ones(*w.shape)\n",
    "    Delta_list = [1e-7, 1e-4, 1e-1]\n",
    "    N = int(2e4)\n",
    "    save_iter = int(1)\n",
    "    tol = 1e-9\n",
    "    methods = []\n",
    "    print(mu, dist[mu])\n",
    "\n",
    "    for Delta in Delta_list:\n",
    "        res[mu][\"delta\"].append(int(np.log10(Delta)))\n",
    "        tol = np.sqrt(6)*Delta\n",
    "\n",
    "        grad_inexact = lambda w: gradf_inexact(w, gradf, Delta, 1, v=v)\n",
    "        method = GradientDescent(AdaptiveL(L0=1, Delta=Delta, Lmin=mu/4), name=\"GD, Delta={}\".format(Delta), save_iter=save_iter)\n",
    "        x = method.solve(w, f, grad_inexact, tol=tol, max_iter=N)\n",
    "        g = lambda: GradientDescent(AdaptiveL(L0=1, Delta=Delta, Lmin=mu/4),\n",
    "                                    return_history=False).solve(w, f, grad_inexact, tol=tol, max_iter=N)\n",
    "        T = timeit.timeit(g, number=number)/number        \n",
    "        print(\"\\t{}\\t{}\\t{:.2f}\\t{:.6f}\\t{:.2f}\".format(Delta, len(method.history), T*1000, np.linalg.norm(x-w), \n",
    "                                                np.linalg.norm(gradf(x))/Delta))\n",
    "        methods.append(method)\n",
    "        res[mu][\"iters_adaptL\"].append(len(method.history))\n",
    "        res[mu][\"time_adaptL\"].append(\"{:.2f}\".format(T*1000))\n",
    "        res[mu][\"adaptL,x0-x*\"].append(\"{:.1f}\".format(np.linalg.norm(x-w)))\n",
    "        res[mu][\"normg_adaptL\"].append(\"{:.2f}\".format(np.linalg.norm(gradf(x))/Delta))\n",
    "\n",
    "\n",
    "        method = AdaptiveNoiseGD(AdaptiveLdelta(L0=1, mindelta=1e-12, Lmin=mu/4, mu=mu), name=\"GD, Delta={}\".format(Delta), save_iter=save_iter, alpha=np.sqrt(6))\n",
    "        x = method.solve(w, f, grad_inexact, max_iter=N)\n",
    "        g = lambda: AdaptiveNoiseGD(AdaptiveLdelta(L0=1, mindelta=1e-12, Lmin=mu/4, mu=mu), return_history=False, \n",
    "                                    alpha=np.sqrt(6)).solve(w, f, grad_inexact, max_iter=N)\n",
    "        T = timeit.timeit(g, number=number)/number        \n",
    "        print(\"\\t{}\\t{}\\t{:.2f}\\t{:.6f}\\t{:.2f}\".format(Delta, len(method.history), T*1000, np.linalg.norm(x-w), \n",
    "                                                np.linalg.norm(gradf(x))/Delta))\n",
    "        methods.append(method)\n",
    "        res[mu][\"iters_adaptLdelta\"].append(len(method.history))\n",
    "        res[mu][\"time_adaptLdelta\"].append(\"{:.2f}\".format(T*1000))\n",
    "        res[mu][\"adaptLdelta,x0-x*\"].append(\"{:.1f}\".format(np.linalg.norm(x-w)))\n",
    "        res[mu][\"normg_adaptLdelta\"].append(\"{:.2f}\".format(np.linalg.norm(gradf(x))/Delta))        \n",
    "\n",
    "        method = GradientDescent(ConstantStepSize(alpha), name=\"GD, Delta={}\".format(Delta), save_iter=save_iter)\n",
    "        x = method.solve(w, f, grad_inexact, tol=tol, max_iter=N)\n",
    "        g = lambda: GradientDescent(ConstantStepSize(alpha),\n",
    "                                    return_history=False).solve(w, f, grad_inexact, tol=tol, max_iter=N)\n",
    "        T = timeit.timeit(g, number=number)/number\n",
    "        print(\"\\t{}\\t{}\\t{:.2f}\\t{:.6f}\\t{:.2f}\".format(Delta, len(method.history), T*1000, np.linalg.norm(x-w), \n",
    "                                                np.linalg.norm(gradf(x))/Delta))\n",
    "        methods.append(method)\n",
    "        res[mu][\"iters_exact\"].append(len(method.history))\n",
    "        res[mu][\"time_exact\"].append(\"{:.2f}\".format(T*1000))\n",
    "        res[mu][\"exact,x0-x*\"].append(\"{:.1f}\".format(np.linalg.norm(x-w)))\n",
    "        res[mu][\"normg_exact\"].append(\"{:.2f}\".format(np.linalg.norm(gradf(x))/Delta))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1525$ \\\\ $837$ \\\\ $158$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $139.02$ \\\\ $76.72$ \\\\ $14.88$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $668$ \\\\ $421$ \\\\ $75$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $243.45$ \\\\ $151.83$ \\\\ $24.67$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.1 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $169$ \\\\ $104$ \\\\ $42$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $15.84$ \\\\ $10.00$ \\\\ $4.40$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $72$ \\\\ $46$ \\\\ $19$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $26.40$ \\\\ $16.39$ \\\\ $6.62$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.9 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $11$ \\\\ $8$ \\\\ $5$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1.56$ \\\\ $1.26$ \\\\ $0.88$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $10$ \\\\ $8$ \\\\ $5$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $3.44$ \\\\ $2.73$ \\\\ $1.65$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.99 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $6$ \\\\ $5$ \\\\ $3$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1.01$ \\\\ $0.92$ \\\\ $0.55$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $6$ \\\\ $5$ \\\\ $3$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.16$ \\\\ $1.75$ \\\\ $1.12$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "\n",
    "for mu in mu_list:\n",
    "    s += str(mu) + \" & \"\n",
    "    cur_list = [\"$10^{{{}}}$\".format(i) for i in res[mu][\"delta\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    \n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"iters_exact\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"time_exact\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"iters_adaptL\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"time_adaptL\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}\"\n",
    "    \n",
    "#     cur_list = [\"${}$\".format(i) for i in res[mu][\"iters_adaptLdelta\"]]\n",
    "#     s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "#     cur_list = [\"${}$\".format(i) for i in res[mu][\"time_adaptLdelta\"]]\n",
    "#     s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}\"\n",
    "\n",
    "    s+= \"\\\\\\\\\\n\\\\hline\\n\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $946.3$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.29$ \\\\ $2.31$ \\\\ $2.29$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $946.7$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.09$ \\\\ $2.33$ \\\\ $1.97$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.1 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.3$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.22$ \\\\ $2.14$ \\\\ $1.94$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.4$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1.99$ \\\\ $2.16$ \\\\ $2.27$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.9 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.7$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.90$ \\\\ $0.94$ \\\\ $0.92$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.6$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.15$ \\\\ $0.98$ \\\\ $0.95$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.99 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.7$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.98$ \\\\ $0.97$ \\\\ $1.04$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.7$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1.03$ \\\\ $1.95$ \\\\ $1.04$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "\n",
    "for mu in mu_list:\n",
    "    s += str(mu) + \" & \"\n",
    "    #s += \"{:.1f}\".format(dist[mu]) + \" & \"\n",
    "    cur_list = [\"$10^{{{}}}$\".format(i) for i in res[mu][\"delta\"]]\n",
    "    \n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"exact,x0-x*\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"normg_exact\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "\n",
    "\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"adaptL,x0-x*\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"normg_adaptL\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}\"\n",
    "    \n",
    "#     cur_list = [\"${}$\".format(i) for i in res[mu][\"adaptLdelta,x0-x*\"]]\n",
    "#     s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "#     cur_list = [\"${}$\".format(i) for i in res[mu][\"normg_adaptLdelta\"]]\n",
    "#     s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}\"\n",
    "\n",
    "    s+= \"\\\\\\\\\\n\\\\hline\\n\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
