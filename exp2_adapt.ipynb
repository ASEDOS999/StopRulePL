{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Experiments 2.2. Quadratic Programming and Adaptive GD\n",
    "\n",
    "Minimization of function\n",
    "\n",
    "$$f(x)=\\sum\\limits_{i=k}^N d_i x_i^2$$\n",
    "for positive $d_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.config import config\n",
    "import timeit\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import gradf_inexact\n",
    "from methods import GradientDescent, parse_logs, AdaptiveL, StepSize, AdaptiveNoiseGD\n",
    "from methods import ConstantStepSize, AdaptiveLdelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')\n",
    "params = {'legend.fontsize': 20,\n",
    "          'legend.handlelength': 4,\n",
    "          \"axes.labelsize\": 45,\n",
    "          \"xtick.labelsize\": 25,\n",
    "          \"ytick.labelsize\": 25,\n",
    "          \"lines.linewidth\": 2,\n",
    "           \"axes.titlesize\":30}\n",
    "matplotlib.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pics = \"../pics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x, A):\n",
    "    m = A.shape[0]\n",
    "    r = A@x\n",
    "    return 1/2 * x.T @ A @ x\n",
    "\n",
    "gradf = jax.grad(f1, argnums=0, has_aux=False)\n",
    "jit_gradf = jax.jit(gradf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Comparison of Theoretical Iterations Count and Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "n = 100\n",
    "k = 10\n",
    "mu = 0.1\n",
    "d = np.zeros(n)\n",
    "d[:k] *= 0\n",
    "d[k:] = np.linspace(mu, 1, n-k)\n",
    "A = np.diag(d)\n",
    "w = np.random.randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals, _ = np.linalg.eigh(A)\n",
    "eigvals.sort()\n",
    "L = np.real(eigvals.max())\n",
    "mu = eigvals[eigvals>=1e-12].min()\n",
    "L, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma=0\n",
    "gradf = lambda x: np.array(jit_gradf(x, A).block_until_ready())\n",
    "f = lambda x: f1(x, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.randn(n)\n",
    "f(np.zeros(A.shape[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The case when $\\xi \\sim \\mathcal{U}(S_1(0))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 948.6832980505138\n",
      "\t1e-07\t511\t226.03\t948.683296\t2.03\n",
      "\t1e-07\t515\t412.39\t948.683297\t1.84\n",
      "\t1e-07\t1525\t142.31\t948.683296\t2.29\n",
      "\n",
      "\t0.0001\t301\t158.16\t948.681419\t2.31\n",
      "\t0.0001\t314\t247.06\t948.681845\t2.43\n",
      "\t0.0001\t840\t75.99\t948.680964\t2.26\n",
      "\n",
      "\t0.1\t85\t33.94\t946.705087\t1.95\n",
      "\t0.1\t170\t103.11\t947.729663\t1.07\n",
      "\t0.1\t159\t14.81\t946.329848\t2.27\n",
      "\n",
      "0.1 948.6832980505138\n",
      "\t1e-07\t76\t29.58\t948.683298\t1.97\n",
      "\t1e-07\t102\t60.81\t948.683298\t0.87\n",
      "\t1e-07\t169\t15.96\t948.683298\t2.17\n",
      "\n",
      "\t0.0001\t49\t18.11\t948.683106\t1.68\n",
      "\t0.0001\t94\t44.58\t948.683195\t0.80\n",
      "\t0.0001\t104\t10.15\t948.683008\t2.18\n",
      "\n",
      "\t0.1\t24\t8.21\t948.310453\t2.26\n",
      "\t0.1\t54\t32.44\t948.541410\t0.83\n",
      "\t0.1\t41\t4.46\t948.267336\t2.14\n",
      "\n",
      "0.9 948.6832980505138\n",
      "\t1e-07\t37\t15.59\t948.683298\t1.58\n",
      "\t1e-07\t72\t36.20\t948.683298\t0.69\n",
      "\t1e-07\t11\t1.57\t948.683298\t0.92\n",
      "\n",
      "\t0.0001\t26\t19.90\t948.683274\t0.96\n",
      "\t0.0001\t48\t51.72\t948.683229\t0.79\n",
      "\t0.0001\t8\t1.28\t948.683288\t0.91\n",
      "\n",
      "\t0.1\t15\t7.92\t948.648986\t0.95\n",
      "\t0.1\t39\t47.80\t948.613786\t0.72\n",
      "\t0.1\t5\t0.90\t948.663619\t0.96\n",
      "\n",
      "0.99 948.6832980505138\n",
      "\t1e-07\t34\t13.38\t948.683298\t0.95\n",
      "\t1e-07\t58\t34.01\t948.683298\t0.71\n",
      "\t1e-07\t6\t1.02\t948.683298\t0.96\n",
      "\n",
      "\t0.0001\t24\t9.21\t948.683287\t0.92\n",
      "\t0.0001\t46\t27.20\t948.683235\t0.68\n",
      "\t0.0001\t5\t0.89\t948.683283\t0.95\n",
      "\n",
      "\t0.1\t14\t5.06\t948.674749\t0.93\n",
      "\t0.1\t48\t24.74\t948.617267\t0.69\n",
      "\t0.1\t3\t0.52\t948.652802\t1.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "np.random.seed(1)\n",
    "n = 100\n",
    "k = 10\n",
    "mu_list = [0.01, 0.1, 0.9, 0.99]\n",
    "res = {mu:{\"delta\":[], \n",
    "           \"iters_adaptL\":[], \"time_adaptL\":[], \"adaptL,x0-x*\": [], \"normg_adaptL\": [],\n",
    "           \"iters_exact\":[], \"time_exact\":[], \"exact,x0-x*\": [], \"normg_exact\": [],\n",
    "          \"iters_adaptLdelta\":[], \"time_adaptLdelta\":[], \"adaptLdelta,x0-x*\": [], \"normg_adaptLdelta\": []} for mu in mu_list}\n",
    "dist = {}\n",
    "number = 200\n",
    "\n",
    "for mu in mu_list:\n",
    "    d = np.zeros(n)\n",
    "    d[:k] *= 0\n",
    "    d[k:] = np.linspace(mu, 1, n-k)\n",
    "    A = np.diag(d)\n",
    "    w = np.random.randn(n)\n",
    "    sigma=0\n",
    "    eigvals, _ = np.linalg.eigh(A)\n",
    "    eigvals.sort()\n",
    "    L = np.real(eigvals.max())\n",
    "    mu = eigvals[eigvals>=1e-12].min()\n",
    "    L, mu\n",
    "    gradf = lambda x: np.array(jit_gradf(x, A).block_until_ready())\n",
    "    f = lambda x: f1(x, A)\n",
    "    f(np.zeros(A.shape[-1]))\n",
    "    alpha = 1/L\n",
    "    w = np.ones(n)*100\n",
    "    wsol = np.where(d!=0, 0, w)\n",
    "    dist[mu] = np.linalg.norm(w-wsol)\n",
    "    v = np.random.randn(*w.shape)\n",
    "    v = np.ones(*w.shape)\n",
    "    Delta_list = [1e-7, 1e-4, 1e-1]\n",
    "    N = int(2e4)\n",
    "    save_iter = int(1)\n",
    "    tol = 1e-9\n",
    "    methods = []\n",
    "    print(mu, dist[mu])\n",
    "\n",
    "    for Delta in Delta_list:\n",
    "        res[mu][\"delta\"].append(int(np.log10(Delta)))\n",
    "        tol = np.sqrt(6)*Delta\n",
    "\n",
    "        grad_inexact = lambda w: gradf_inexact(w, gradf, Delta, 1, v=v)\n",
    "        method = GradientDescent(AdaptiveL(L0=1, Delta=Delta, Lmin=mu/4), name=\"GD, Delta={}\".format(Delta), save_iter=save_iter)\n",
    "        x = method.solve(w, f, grad_inexact, tol=tol, max_iter=N)\n",
    "        g = lambda: GradientDescent(AdaptiveL(L0=1, Delta=Delta, Lmin=mu/4),\n",
    "                                    return_history=False).solve(w, f, grad_inexact, tol=tol, max_iter=N)\n",
    "        T = timeit.timeit(g, number=number)/number        \n",
    "        print(\"\\t{}\\t{}\\t{:.2f}\\t{:.6f}\\t{:.2f}\".format(Delta, len(method.history), T*1000, np.linalg.norm(x-w), \n",
    "                                                np.linalg.norm(gradf(x))/Delta))\n",
    "        methods.append(method)\n",
    "        res[mu][\"iters_adaptL\"].append(len(method.history))\n",
    "        res[mu][\"time_adaptL\"].append(\"{:.2f}\".format(T*1000))\n",
    "        res[mu][\"adaptL,x0-x*\"].append(\"{:.1f}\".format(np.linalg.norm(x-w)))\n",
    "        res[mu][\"normg_adaptL\"].append(\"{:.2f}\".format(np.linalg.norm(gradf(x))/Delta))\n",
    "\n",
    "\n",
    "        method = AdaptiveNoiseGD(AdaptiveLdelta(L0=1, mindelta=1e-12, Lmin=mu/4, mu=mu), name=\"GD, Delta={}\".format(Delta), save_iter=save_iter, alpha=np.sqrt(6))\n",
    "        x = method.solve(w, f, grad_inexact, max_iter=N)\n",
    "        g = lambda: AdaptiveNoiseGD(AdaptiveLdelta(L0=1, mindelta=1e-12, Lmin=mu/4, mu=mu), return_history=False, \n",
    "                                    alpha=np.sqrt(6)).solve(w, f, grad_inexact, max_iter=N)\n",
    "        T = timeit.timeit(g, number=number)/number        \n",
    "        print(\"\\t{}\\t{}\\t{:.2f}\\t{:.6f}\\t{:.2f}\".format(Delta, len(method.history), T*1000, np.linalg.norm(x-w), \n",
    "                                                np.linalg.norm(gradf(x))/Delta))\n",
    "        methods.append(method)\n",
    "        res[mu][\"iters_adaptLdelta\"].append(len(method.history))\n",
    "        res[mu][\"time_adaptLdelta\"].append(\"{:.2f}\".format(T*1000))\n",
    "        res[mu][\"adaptLdelta,x0-x*\"].append(\"{:.1f}\".format(np.linalg.norm(x-w)))\n",
    "        res[mu][\"normg_adaptLdelta\"].append(\"{:.2f}\".format(np.linalg.norm(gradf(x))/Delta))        \n",
    "\n",
    "        method = GradientDescent(ConstantStepSize(alpha), name=\"GD, Delta={}\".format(Delta), save_iter=save_iter)\n",
    "        x = method.solve(w, f, grad_inexact, tol=tol, max_iter=N)\n",
    "        g = lambda: GradientDescent(ConstantStepSize(alpha),\n",
    "                                    return_history=False).solve(w, f, grad_inexact, tol=tol, max_iter=N)\n",
    "        T = timeit.timeit(g, number=number)/number\n",
    "        print(\"\\t{}\\t{}\\t{:.2f}\\t{:.6f}\\t{:.2f}\".format(Delta, len(method.history), T*1000, np.linalg.norm(x-w), \n",
    "                                                np.linalg.norm(gradf(x))/Delta))\n",
    "        methods.append(method)\n",
    "        res[mu][\"iters_exact\"].append(len(method.history))\n",
    "        res[mu][\"time_exact\"].append(\"{:.2f}\".format(T*1000))\n",
    "        res[mu][\"exact,x0-x*\"].append(\"{:.1f}\".format(np.linalg.norm(x-w)))\n",
    "        res[mu][\"normg_exact\"].append(\"{:.2f}\".format(np.linalg.norm(gradf(x))/Delta))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $511$ \\\\ $301$ \\\\ $85$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $226.03$ \\\\ $158.16$ \\\\ $33.94$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $515$ \\\\ $314$ \\\\ $170$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $412.39$ \\\\ $247.06$ \\\\ $103.11$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.1 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $76$ \\\\ $49$ \\\\ $24$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $29.58$ \\\\ $18.11$ \\\\ $8.21$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $102$ \\\\ $94$ \\\\ $54$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $60.81$ \\\\ $44.58$ \\\\ $32.44$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.9 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $37$ \\\\ $26$ \\\\ $15$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $15.59$ \\\\ $19.90$ \\\\ $7.92$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $72$ \\\\ $48$ \\\\ $39$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $36.20$ \\\\ $51.72$ \\\\ $47.80$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.99 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $34$ \\\\ $24$ \\\\ $14$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $13.38$ \\\\ $9.21$ \\\\ $5.06$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $58$ \\\\ $46$ \\\\ $48$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $34.01$ \\\\ $27.20$ \\\\ $24.74$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "\n",
    "for mu in mu_list:\n",
    "    s += str(mu) + \" & \"\n",
    "    cur_list = [\"$10^{{{}}}$\".format(i) for i in res[mu][\"delta\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    \n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"iters_exact\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"time_exact\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"iters_adaptL\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"time_adaptL\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    \n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"iters_adaptLdelta\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"time_adaptLdelta\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}\"\n",
    "\n",
    "    s+= \"\\\\\\\\\\n\\\\hline\\n\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $946.3$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.29$ \\\\ $2.26$ \\\\ $2.27$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $946.7$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.03$ \\\\ $2.31$ \\\\ $1.95$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $947.7$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1.84$ \\\\ $2.43$ \\\\ $1.07$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.1 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.3$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.17$ \\\\ $2.18$ \\\\ $2.14$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.3$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1.97$ \\\\ $1.68$ \\\\ $2.26$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.5$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.87$ \\\\ $0.80$ \\\\ $0.83$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.9 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.7$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.92$ \\\\ $0.91$ \\\\ $0.96$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.6$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1.58$ \\\\ $0.96$ \\\\ $0.95$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.6$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.69$ \\\\ $0.79$ \\\\ $0.72$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.99 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.7$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.96$ \\\\ $0.95$ \\\\ $1.05$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.7$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.95$ \\\\ $0.92$ \\\\ $0.93$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.6$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.71$ \\\\ $0.68$ \\\\ $0.69$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "\n",
    "for mu in mu_list:\n",
    "    s += str(mu) + \" & \"\n",
    "    #s += \"{:.1f}\".format(dist[mu]) + \" & \"\n",
    "    cur_list = [\"$10^{{{}}}$\".format(i) for i in res[mu][\"delta\"]]\n",
    "    \n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"exact,x0-x*\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"normg_exact\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "\n",
    "\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"adaptL,x0-x*\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"normg_adaptL\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    \n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"adaptLdelta,x0-x*\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"normg_adaptLdelta\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}\"\n",
    "\n",
    "    s+= \"\\\\\\\\\\n\\\\hline\\n\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
