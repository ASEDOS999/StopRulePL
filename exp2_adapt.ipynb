{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Experiments 2.2. Quadratic Programming and Adaptive GD\n",
    "\n",
    "Minimization of function\n",
    "\n",
    "$$f(x)=\\sum\\limits_{i=k}^N d_i x_i^2$$\n",
    "for positive $d_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.config import config\n",
    "import timeit\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import gradf_inexact\n",
    "from methods import GradientDescent, parse_logs, AdaptiveL, StepSize, AdaptiveNoiseGD\n",
    "from methods import ConstantStepSize, AdaptiveLdelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')\n",
    "params = {'legend.fontsize': 20,\n",
    "          'legend.handlelength': 4,\n",
    "          \"axes.labelsize\": 45,\n",
    "          \"xtick.labelsize\": 25,\n",
    "          \"ytick.labelsize\": 25,\n",
    "          \"lines.linewidth\": 2,\n",
    "           \"axes.titlesize\":30}\n",
    "matplotlib.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pics = \"../pics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x, A):\n",
    "    m = A.shape[0]\n",
    "    r = A@x\n",
    "    return 1/2 * x.T @ A @ x\n",
    "\n",
    "gradf = jax.grad(f1, argnums=0, has_aux=False)\n",
    "jit_gradf = jax.jit(gradf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Comparison of Theoretical Iterations Count and Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "n = 100\n",
    "k = 10\n",
    "mu = 0.1\n",
    "d = np.zeros(n)\n",
    "d[:k] *= 0\n",
    "d[k:] = np.linspace(mu, 1, n-k)\n",
    "A = np.diag(d)\n",
    "w = np.random.randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals, _ = np.linalg.eigh(A)\n",
    "eigvals.sort()\n",
    "L = np.real(eigvals.max())\n",
    "mu = eigvals[eigvals>=1e-12].min()\n",
    "L, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma=0\n",
    "gradf = lambda x: np.array(jit_gradf(x, A).block_until_ready())\n",
    "f = lambda x: f1(x, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.randn(n)\n",
    "f(np.zeros(A.shape[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The case when $\\xi \\sim \\mathcal{U}(S_1(0))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 948.6832980505138\n",
      "\t0.001\t225\t105.52\t948.663411\t2.21\n",
      "\t0.001\t300\t180.61\t948.673899\t1.09\n",
      "\t0.001\t607\t57.03\t948.659351\t2.32\n",
      "\n",
      "\t0.0001\t291\t122.95\t948.680923\t2.30\n",
      "\t0.0001\t343\t205.60\t948.682199\t1.72\n",
      "\t0.0001\t839\t78.38\t948.680962\t2.31\n",
      "\n",
      "\t0.1\t76\t30.81\t946.396069\t2.33\n",
      "\t0.1\t173\t99.76\t947.713411\t1.03\n",
      "\t0.1\t155\t14.76\t946.209419\t2.37\n",
      "\n",
      "0.1 948.6832980505138\n",
      "\t0.001\t38\t15.37\t948.680611\t2.08\n",
      "\t0.001\t82\t45.09\t948.682296\t0.80\n",
      "\t0.001\t82\t8.14\t948.679989\t2.24\n",
      "\n",
      "\t0.0001\t48\t18.86\t948.683017\t2.19\n",
      "\t0.0001\t92\t45.37\t948.683201\t0.76\n",
      "\t0.0001\t103\t9.98\t948.682966\t2.34\n",
      "\n",
      "\t0.1\t22\t8.51\t948.385163\t1.87\n",
      "\t0.1\t67\t33.33\t948.545225\t0.81\n",
      "\t0.1\t41\t4.48\t948.252326\t2.16\n",
      "\n",
      "0.9 948.6832980505138\n",
      "\t0.001\t22\t7.87\t948.682921\t0.92\n",
      "\t0.001\t42\t24.85\t948.682601\t0.76\n",
      "\t0.001\t7\t1.13\t948.683210\t0.90\n",
      "\n",
      "\t0.0001\t26\t10.27\t948.683294\t0.88\n",
      "\t0.0001\t45\t26.67\t948.683238\t0.70\n",
      "\t0.0001\t8\t1.24\t948.683269\t0.93\n",
      "\n",
      "\t0.1\t15\t5.39\t948.666445\t0.89\n",
      "\t0.1\t38\t20.70\t948.611310\t0.74\n",
      "\t0.1\t5\t0.88\t948.655075\t0.95\n",
      "\n",
      "0.99 948.6832980505138\n",
      "\t0.001\t20\t7.69\t948.681319\t2.06\n",
      "\t0.001\t45\t25.39\t948.682631\t0.71\n",
      "\t0.001\t4\t0.76\t948.682973\t0.98\n",
      "\n",
      "\t0.0001\t24\t9.19\t948.683171\t1.39\n",
      "\t0.0001\t47\t26.27\t948.683226\t0.75\n",
      "\t0.0001\t5\t0.88\t948.683302\t0.89\n",
      "\n",
      "\t0.1\t14\t5.90\t948.561708\t1.33\n",
      "\t0.1\t36\t22.52\t948.618643\t0.69\n",
      "\t0.1\t3\t0.53\t948.660287\t1.10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "np.random.seed(1)\n",
    "n = 100\n",
    "k = 10\n",
    "mu_list = [0.01, 0.1, 0.9, 0.99]\n",
    "res = {mu:{\"delta\":[], \n",
    "           \"iters_adaptL\":[], \"time_adaptL\":[], \"adaptL,x0-x*\": [], \"normg_adaptL\": [],\n",
    "           \"iters_exact\":[], \"time_exact\":[], \"exact,x0-x*\": [], \"normg_exact\": [],\n",
    "          \"iters_adaptLdelta\":[], \"time_adaptLdelta\":[], \"adaptLdelta,x0-x*\": [], \"normg_adaptLdelta\": []} for mu in mu_list}\n",
    "dist = {}\n",
    "number = 200\n",
    "\n",
    "for mu in mu_list:\n",
    "    d = np.zeros(n)\n",
    "    d[:k] *= 0\n",
    "    d[k:] = np.linspace(mu, 1, n-k)\n",
    "    A = np.diag(d)\n",
    "    w = np.random.randn(n)\n",
    "    sigma=0\n",
    "    eigvals, _ = np.linalg.eigh(A)\n",
    "    eigvals.sort()\n",
    "    L = np.real(eigvals.max())\n",
    "    mu = eigvals[eigvals>=1e-12].min()\n",
    "    L, mu\n",
    "    gradf = lambda x: np.array(jit_gradf(x, A).block_until_ready())\n",
    "    f = lambda x: f1(x, A)\n",
    "    f(np.zeros(A.shape[-1]))\n",
    "    alpha = 1/L\n",
    "    w = np.ones(n)*100\n",
    "    wsol = np.where(d!=0, 0, w)\n",
    "    dist[mu] = np.linalg.norm(w-wsol)\n",
    "    v = np.random.randn(*w.shape)\n",
    "    v = np.ones(*w.shape)\n",
    "    Delta_list = [1e-3, 1e-4, 1e-1]\n",
    "    N = int(2e4)\n",
    "    save_iter = int(1)\n",
    "    tol = 1e-9\n",
    "    methods = []\n",
    "    print(mu, dist[mu])\n",
    "\n",
    "    for Delta in Delta_list:\n",
    "        res[mu][\"delta\"].append(int(np.log10(Delta)))\n",
    "        tol = np.sqrt(6)*Delta\n",
    "\n",
    "        grad_inexact = lambda w: gradf_inexact(w, gradf, Delta, 1, v=v)\n",
    "        method = GradientDescent(AdaptiveL(L0=1, Delta=Delta, Lmin=mu/4), name=\"GD, Delta={}\".format(Delta), save_iter=save_iter)\n",
    "        x = method.solve(w, f, grad_inexact, tol=tol, max_iter=N)\n",
    "        g = lambda: GradientDescent(AdaptiveL(L0=1, Delta=Delta, Lmin=mu/4),\n",
    "                                    return_history=False).solve(w, f, grad_inexact, tol=tol, max_iter=N)\n",
    "        T = timeit.timeit(g, number=number)/number        \n",
    "        print(\"\\t{}\\t{}\\t{:.2f}\\t{:.6f}\\t{:.2f}\".format(Delta, len(method.history), T*1000, np.linalg.norm(x-w), \n",
    "                                                np.linalg.norm(gradf(x))/Delta))\n",
    "        methods.append(method)\n",
    "        res[mu][\"iters_adaptL\"].append(len(method.history))\n",
    "        res[mu][\"time_adaptL\"].append(\"{:.2f}\".format(T*1000))\n",
    "        res[mu][\"adaptL,x0-x*\"].append(\"{:.1f}\".format(np.linalg.norm(x-w)))\n",
    "        res[mu][\"normg_adaptL\"].append(\"{:.2f}\".format(np.linalg.norm(gradf(x))/Delta))\n",
    "\n",
    "\n",
    "        method = AdaptiveNoiseGD(AdaptiveLdelta(L0=1, mindelta=1e-12, Lmin=mu/4, mu=mu), name=\"GD, Delta={}\".format(Delta), save_iter=save_iter, alpha=np.sqrt(6))\n",
    "        x = method.solve(w, f, grad_inexact, max_iter=N)\n",
    "        g = lambda: AdaptiveNoiseGD(AdaptiveLdelta(L0=1, mindelta=1e-12, Lmin=mu/4, mu=mu), return_history=False, \n",
    "                                    alpha=np.sqrt(6)).solve(w, f, grad_inexact, max_iter=N)\n",
    "        T = timeit.timeit(g, number=number)/number        \n",
    "        print(\"\\t{}\\t{}\\t{:.2f}\\t{:.6f}\\t{:.2f}\".format(Delta, len(method.history), T*1000, np.linalg.norm(x-w), \n",
    "                                                np.linalg.norm(gradf(x))/Delta))\n",
    "        methods.append(method)\n",
    "        res[mu][\"iters_adaptLdelta\"].append(len(method.history))\n",
    "        res[mu][\"time_adaptLdelta\"].append(\"{:.2f}\".format(T*1000))\n",
    "        res[mu][\"adaptLdelta,x0-x*\"].append(\"{:.1f}\".format(np.linalg.norm(x-w)))\n",
    "        res[mu][\"normg_adaptLdelta\"].append(\"{:.2f}\".format(np.linalg.norm(gradf(x))/Delta))        \n",
    "\n",
    "        method = GradientDescent(ConstantStepSize(alpha), name=\"GD, Delta={}\".format(Delta), save_iter=save_iter)\n",
    "        x = method.solve(w, f, grad_inexact, tol=tol, max_iter=N)\n",
    "        g = lambda: GradientDescent(ConstantStepSize(alpha),\n",
    "                                    return_history=False).solve(w, f, grad_inexact, tol=tol, max_iter=N)\n",
    "        T = timeit.timeit(g, number=number)/number\n",
    "        print(\"\\t{}\\t{}\\t{:.2f}\\t{:.6f}\\t{:.2f}\".format(Delta, len(method.history), T*1000, np.linalg.norm(x-w), \n",
    "                                                np.linalg.norm(gradf(x))/Delta))\n",
    "        methods.append(method)\n",
    "        res[mu][\"iters_exact\"].append(len(method.history))\n",
    "        res[mu][\"time_exact\"].append(\"{:.2f}\".format(T*1000))\n",
    "        res[mu][\"exact,x0-x*\"].append(\"{:.1f}\".format(np.linalg.norm(x-w)))\n",
    "        res[mu][\"normg_exact\"].append(\"{:.2f}\".format(np.linalg.norm(gradf(x))/Delta))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 & \\begin{tabular}{@{}c@{}} $10^{-3}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $607$ \\\\ $839$ \\\\ $155$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $57.03$ \\\\ $78.38$ \\\\ $14.76$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $225$ \\\\ $291$ \\\\ $76$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $105.52$ \\\\ $122.95$ \\\\ $30.81$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $300$ \\\\ $343$ \\\\ $173$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $180.61$ \\\\ $205.60$ \\\\ $99.76$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.1 & \\begin{tabular}{@{}c@{}} $10^{-3}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $82$ \\\\ $103$ \\\\ $41$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $8.14$ \\\\ $9.98$ \\\\ $4.48$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $38$ \\\\ $48$ \\\\ $22$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $15.37$ \\\\ $18.86$ \\\\ $8.51$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $82$ \\\\ $92$ \\\\ $67$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $45.09$ \\\\ $45.37$ \\\\ $33.33$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.9 & \\begin{tabular}{@{}c@{}} $10^{-3}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $7$ \\\\ $8$ \\\\ $5$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1.13$ \\\\ $1.24$ \\\\ $0.88$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $22$ \\\\ $26$ \\\\ $15$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $7.87$ \\\\ $10.27$ \\\\ $5.39$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $42$ \\\\ $45$ \\\\ $38$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $24.85$ \\\\ $26.67$ \\\\ $20.70$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.99 & \\begin{tabular}{@{}c@{}} $10^{-3}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $4$ \\\\ $5$ \\\\ $3$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.76$ \\\\ $0.88$ \\\\ $0.53$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $20$ \\\\ $24$ \\\\ $14$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $7.69$ \\\\ $9.19$ \\\\ $5.90$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $45$ \\\\ $47$ \\\\ $36$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $25.39$ \\\\ $26.27$ \\\\ $22.52$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "\n",
    "for mu in mu_list:\n",
    "    s += str(mu) + \" & \"\n",
    "    cur_list = [\"$10^{{{}}}$\".format(i) for i in res[mu][\"delta\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    \n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"iters_exact\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"time_exact\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"iters_adaptL\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"time_adaptL\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    \n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"iters_adaptLdelta\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"time_adaptLdelta\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}\"\n",
    "\n",
    "    s+= \"\\\\\\\\\\n\\\\hline\\n\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 & \\begin{tabular}{@{}c@{}} $10^{-3}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $946.2$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.32$ \\\\ $2.31$ \\\\ $2.37$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $946.4$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.21$ \\\\ $2.30$ \\\\ $2.33$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $947.7$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1.09$ \\\\ $1.72$ \\\\ $1.03$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.1 & \\begin{tabular}{@{}c@{}} $10^{-3}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.3$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.24$ \\\\ $2.34$ \\\\ $2.16$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.4$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.08$ \\\\ $2.19$ \\\\ $1.87$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.5$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.80$ \\\\ $0.76$ \\\\ $0.81$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.9 & \\begin{tabular}{@{}c@{}} $10^{-3}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.7$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.90$ \\\\ $0.93$ \\\\ $0.95$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.7$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.92$ \\\\ $0.88$ \\\\ $0.89$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.6$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.76$ \\\\ $0.70$ \\\\ $0.74$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "0.99 & \\begin{tabular}{@{}c@{}} $10^{-3}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.7$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.98$ \\\\ $0.89$ \\\\ $1.10$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.6$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.06$ \\\\ $1.39$ \\\\ $1.33$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $948.7$ \\\\ $948.7$ \\\\ $948.6$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.71$ \\\\ $0.75$ \\\\ $0.69$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "\n",
    "for mu in mu_list:\n",
    "    s += str(mu) + \" & \"\n",
    "    #s += \"{:.1f}\".format(dist[mu]) + \" & \"\n",
    "    cur_list = [\"$10^{{{}}}$\".format(i) for i in res[mu][\"delta\"]]\n",
    "    \n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"exact,x0-x*\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"normg_exact\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "\n",
    "\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"adaptL,x0-x*\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"normg_adaptL\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    \n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"adaptLdelta,x0-x*\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[mu][\"normg_adaptLdelta\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}\"\n",
    "\n",
    "    s+= \"\\\\\\\\\\n\\\\hline\\n\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
