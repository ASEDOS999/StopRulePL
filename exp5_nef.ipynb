{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Experiments 1. Non-linear Equation System: sinus\n",
    "\n",
    "We will minimize\n",
    "\n",
    "$$f(w_1, w_2) = \\sum\\limits_{i=1}^d \\left(\\langle w_1, x_i\\rangle + \\sin\\left(w_2, x_i\\right) - y_i\\right)^2$$\n",
    "\n",
    "for $w_1, w_2\\in\\mathbb{R}^n$, $x_i \\in \\mathbb{R}^n$, $d\\leq n$ with the condition\n",
    "\n",
    "$$XX^\\top \\succeq \\mu I_d,$$\n",
    "where $X = (x_1 \\dots x_d)^\\top \\in \\mathbb{R}^{d\\times n}.$\n",
    "\n",
    "Now we will use spherical approximation\n",
    "\n",
    "$$\\tilde{\\nabla}f(x)=\\frac{n}{h}\\mathbb{E}\\tilde{f}(x+eh)e$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import timeit\n",
    "from jax.config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import gradf_inexact\n",
    "from methods import GradientDescent, parse_logs, AdaptiveL, StepSize, AdaptiveNoiseGD\n",
    "from methods import ConstantStepSize, AdaptiveLdelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')\n",
    "params = {'legend.fontsize': 20,\n",
    "          'legend.handlelength': 4,\n",
    "          \"axes.labelsize\": 45,\n",
    "          \"xtick.labelsize\": 25,\n",
    "          \"ytick.labelsize\": 25,\n",
    "          \"lines.linewidth\": 2,\n",
    "           \"axes.titlesize\":30}\n",
    "matplotlib.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pics = \"../pics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(w1, w2, X, Y):\n",
    "    G = (X @ w1 + jnp.sin(X@w2) - Y)**2\n",
    "    return G.sum(axis=0)\n",
    "gradf = jax.grad(f1, argnums=(0, 1), has_aux=False)\n",
    "jit_gradf = jax.jit(gradf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12308191420612347"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.932412249490965, 83.66651720351642)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 20\n",
    "n = 30\n",
    "X = np.random.randn(d, n)\n",
    "w = np.random.randn(2*n)\n",
    "Y = X @ w[:n] + np.sin(X@w[n:])\n",
    "eig = np.linalg.eig(X@X.T)[0]\n",
    "mu = min(eig)\n",
    "min(eig), max(eig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma=0\n",
    "def gradf(x):\n",
    "    z = jit_gradf(x[:n], x[n:], X, Y)\n",
    "    g = np.hstack([np.array(i.block_until_ready()) for i in z])\n",
    "    return g\n",
    "f = lambda x: f1(x[:n], x[n:], X, Y, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params(X, Y, delta, h, K):\n",
    "    f = lambda x: f1(x[:n], x[n:], X, Y)  + delta * np.random.uniform(-1, 1)\n",
    "    def gradf(x):\n",
    "        s = np.zeros(2 * X.shape[-1])\n",
    "        for k in range(K):\n",
    "            e = np.random.randn(2 * X.shape[-1])\n",
    "            e /= np.linalg.norm(e)\n",
    "            s +=  f(x + e * h) * e\n",
    "        return 2 * X.shape[-1] / h * s/K\n",
    "    return f, gradf\n",
    "\n",
    "\n",
    "def params(X, Y, delta, h, K):\n",
    "    f = lambda x: f1(x[:n], x[n:], X, Y)  + delta * np.random.uniform(-1, 1)\n",
    "    def gradf(x):\n",
    "        z = jit_gradf(x[:n], x[n:], X, Y)\n",
    "        g = np.hstack([np.array(i.block_until_ready()) for i in z])\n",
    "        return g\n",
    "    return f, gradf\n",
    "\n",
    "eps = 1e-10\n",
    "h = 3e-1 * np.sqrt(eps)\n",
    "f, gradf = params(X, Y, eps, h, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fexact' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-80fd7309fde6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfexact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fexact' is not defined"
     ]
    }
   ],
   "source": [
    "f(w).item(), f(w)-fexact(w[:n], w[n:], X, Y), np.linalg.norm(gradf(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Noise Distributed on the Unit Sphere\n",
    "\n",
    "The case when $\\xi \\sim \\mathcal{U}(S_1(0))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 18.977936872901132\n",
      "\t0.0001\t35\t81.74\t1.419305\t3.76\t1.0121319182649616e-08\n",
      "\t0.001\t27\t63.31\t1.419739\t19.66\t3.905218190818588e-06\n",
      "\t0.01\t19\t44.94\t1.419447\t0.61\t2.338044129518015e-05\n",
      "\n",
      "\n",
      "10 6.8029268057078705\n",
      "\t0.0001\t52\t127.01\t5.348248\t24.49\t2.7406010311450852e-08\n",
      "\t0.001\t38\t103.05\t5.350924\t285.78\t0.00044947126057567227\n",
      "\t0.01\t32\t79.38\t5.346481\t7.82\t6.166135357481751e-05\n",
      "\n",
      "\n",
      "20 0.6445302383410392\n",
      "\t0.0001\t108\t317.40\t4.242053\t45.55\t8.653600035852517e-07\n",
      "\t0.001\t79\t219.05\t4.240251\t30.82\t5.9551214634589696e-05\n",
      "\t0.01\t45\t126.00\t4.217464\t42.85\t0.009108292438334473\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eps_list = [1e-8, 1e-6, 1e-4]\n",
    "\n",
    "n = 30\n",
    "d_list = [2, 10, 20]\n",
    "\n",
    "w = np.ones(2*n)\n",
    "v = np.random.randn(2*n)\n",
    "res = {d:{\"delta\":[], \n",
    "           \"iters_adaptL\":[], \"time_adaptL\":[], \"adaptL,x0-x*\": [], \"normg_adaptL\": [],\n",
    "           \"iters_exact\":[], \"time_exact\":[], \"exact,x0-x*\": [], \"normg_exact\": [],\n",
    "          \"iters_adaptLdelta\":[], \"time_adaptLdelta\":[], \"adaptLdelta,x0-x*\": [], \"normg_adaptLdelta\": []} for d in d_list}\n",
    "mu_list = {}\n",
    "number = 10\n",
    "save_iter = 1\n",
    "N = 10000\n",
    "methods = []\n",
    "np.random.seed(1)\n",
    "for d in d_list:\n",
    "    X = np.random.randn(d, n)\n",
    "    w = np.random.randn(2*n)\n",
    "    Y = X @ w[:n] + np.sin(X@w[n:])\n",
    "    eig = np.linalg.eig(X@X.T)[0]\n",
    "    wsol=w.copy()\n",
    "    w = np.ones(2*n)\n",
    "    v = np.random.randn(2*n)\n",
    "    mu = min(eig)\n",
    "\n",
    "    mu_list[d] = mu\n",
    "    print(d, mu)\n",
    "    for eps in eps_list:\n",
    "        h = 3e-1 * np.sqrt(eps)\n",
    "        Delta = np.sqrt(eps)\n",
    "        f, gradf = params(X, Y, eps, h, 10)\n",
    "        res[d][\"delta\"].append(int(np.log10(Delta)))\n",
    "        tol = 2*Delta\n",
    "\n",
    "        grad_inexact = gradf\n",
    "        grad_inexact = lambda w: gradf_inexact(w, gradf, Delta, 1, v=v)\n",
    "        stepsize = AdaptiveLdelta(L0=1, mindelta=1e-12, Lmin=mu/4, mu=mu, delta_alpha=2.1)\n",
    "        method = AdaptiveNoiseGD(stepsize, name=\"GD, Delta={}\".format(Delta), save_iter=save_iter, alpha=np.sqrt(6))\n",
    "        x = method.solve(w, f, grad_inexact, max_iter=N)\n",
    "        g = lambda: AdaptiveNoiseGD(AdaptiveLdelta(L0=1, mindelta=1e-12, Lmin=mu/4, mu=mu, delta_alpha=2), return_history=False, \n",
    "                                    alpha=np.sqrt(6)).solve(w, f, grad_inexact, max_iter=N)\n",
    "        T = timeit.timeit(g, number=number)/number        \n",
    "        print(\"\\t{}\\t{}\\t{:.2f}\\t{:.6f}\\t{:.2f}\\t{}\".format(Delta, len(method.history), T*1000, np.linalg.norm(x-w), \n",
    "                                                np.linalg.norm(gradf(x))/Delta, f(x)))\n",
    "        methods.append(method)\n",
    "        res[d][\"iters_adaptLdelta\"].append(len(method.history))\n",
    "        res[d][\"time_adaptLdelta\"].append(\"{:.2f}\".format(T*1000))\n",
    "        res[d][\"adaptLdelta,x0-x*\"].append(\"{:.1f}\".format(np.linalg.norm(x-w)))\n",
    "        res[d][\"normg_adaptLdelta\"].append(\"{:.2f}\".format(np.linalg.norm(gradf(x))/Delta))    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\n",
    "\n",
    "for d in d_list:\n",
    "    s += str(d) + \" & \"\n",
    "    s += \"{:.1f}\".format(mu_list[d]) + \" & \"\n",
    "\n",
    "    cur_list = [\"$10^{{{}}}$\".format(i) for i in res[d][\"delta\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "\n",
    "    cur_list = [\"${}$\".format(i) for i in res[d][\"iters_adaptL\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[d][\"time_adaptL\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    \n",
    "    cur_list = [\"${}$\".format(i) for i in res[d][\"iters_adaptLdelta\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[d][\"time_adaptLdelta\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}\"\n",
    "\n",
    "    s+= \"\\\\\\\\\\n\\\\hline\\n\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $3.5$ \\\\ $3.5$ \\\\ $3.5$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.23$ \\\\ $0.21$ \\\\ $1.63$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $3.5$ \\\\ $3.5$ \\\\ $3.5$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1.75$ \\\\ $0.72$ \\\\ $0.67$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "50 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $10.2$ \\\\ $10.2$ \\\\ $10.2$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1.38$ \\\\ $1.40$ \\\\ $1.33$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $10.2$ \\\\ $10.2$ \\\\ $10.2$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.72$ \\\\ $1.66$ \\\\ $1.72$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "100 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $14.8$ \\\\ $14.8$ \\\\ $14.8$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1.58$ \\\\ $1.39$ \\\\ $1.61$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $14.8$ \\\\ $14.8$ \\\\ $14.8$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.56$ \\\\ $1.73$ \\\\ $3.38$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "200 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $18.8$ \\\\ $18.8$ \\\\ $18.8$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1.66$ \\\\ $1.70$ \\\\ $1.67$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $18.8$ \\\\ $18.8$ \\\\ $18.8$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $3.48$ \\\\ $1.71$ \\\\ $1.76$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "250 & \\begin{tabular}{@{}c@{}} $10^{-7}$ \\\\ $10^{-4}$ \\\\ $10^{-1}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $21.9$ \\\\ $21.9$ \\\\ $21.9$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1.68$ \\\\ $1.74$ \\\\ $1.69$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $21.9$ \\\\ $21.9$ \\\\ $21.9$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.81$ \\\\ $1.71$ \\\\ $1.74$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "\n",
    "for d in d_list:\n",
    "    s += str(d) + \" & \"\n",
    "    cur_list = [\"$10^{{{}}}$\".format(i) for i in res[d][\"delta\"]]\n",
    "\n",
    "\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[d][\"adaptL,x0-x*\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[d][\"normg_adaptL\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    \n",
    "    cur_list = [\"${}$\".format(i) for i in res[d][\"adaptLdelta,x0-x*\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[d][\"normg_adaptLdelta\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}\"\n",
    "\n",
    "    s+= \"\\\\\\\\\\n\\\\hline\\n\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
