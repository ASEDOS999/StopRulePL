{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Experiments 7. Nesterov-Skokov Function with Antigradient inexactness\n",
    "\n",
    "We will minimize\n",
    "\n",
    "$$f(x) = \\frac{1}{4}(1-x_1)^2+\\sum\\limits_{i=1}^{n-1}\\left(x_{i+1}-2x_i^2 + 1\\right)^2.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import timeit\n",
    "from jax.config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import gradf_inexact\n",
    "from methods import GradientDescent, parse_logs, AdaptiveL, StepSize, AdaptiveNoiseGD\n",
    "from methods import ConstantStepSize, AdaptiveLdelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')\n",
    "params = {'legend.fontsize': 20,\n",
    "          'legend.handlelength': 4,\n",
    "          \"axes.labelsize\": 45,\n",
    "          \"xtick.labelsize\": 25,\n",
    "          \"ytick.labelsize\": 25,\n",
    "          \"lines.linewidth\": 2,\n",
    "           \"axes.titlesize\":30}\n",
    "matplotlib.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pics = \"../pics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f1(x, n):\n",
    "    G = 1/4*(1-x[0])**2\n",
    "    for i in range(n-1):\n",
    "        G += (x[i+1] - 2 * x[i]**2 +1)**2\n",
    "    return G.sum()\n",
    "gradf = jax.grad(f1, argnums=(0,), has_aux=False)\n",
    "jit_gradf = jax.jit(gradf)\n",
    "gradf = lambda x: np.hstack([np.array(i.block_until_ready()) for i in jit_gradf(x)])\n",
    "\n",
    "def get_params(n):\n",
    "    f = lambda x: f1(x, n)\n",
    "    gradf = jax.grad(f, argnums=(0,), has_aux=False)\n",
    "    jit_gradf = jax.jit(gradf)\n",
    "    gradf = lambda x: np.hstack([np.array(i.block_until_ready()) for i in jit_gradf(x)])\n",
    "    return gradf, f\n",
    "gradf, f = get_params(2)\n",
    "gradf(np.ones(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Noise Distributed on the Unit Sphere\n",
    "\n",
    "The case when $\\xi \\sim \\mathcal{U}(S_1(0))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "1.0 1.0\n",
      "1e-08\n",
      "\t0.0001\t13703\t247.73\t1.996551\t2.99\t2.2389726785421574e-05\n",
      "\n",
      "\n",
      "1e-06\n",
      "\t0.001\t2531\t258.80\t2.163126\t2.99\t0.0012053276867817668\n",
      "\n",
      "\n",
      "0.0001\n",
      "\t0.01\t498\t394.30\t2.751641\t2.97\t0.012898109089983944\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "1.0 1.0\n",
      "1e-08\n",
      "\t0.0001\t55452\t303.51\t2.893251\t3.00\t0.00035770029365469417\n",
      "\n",
      "\n",
      "1e-06\n",
      "\t0.001\t15295\t298.79\t3.338827\t2.80\t0.0051303037949482575\n",
      "\n",
      "\n",
      "0.0001\n",
      "\t0.01\t5\t60.15\t0.035755\t2.06\t0.9830358914472521\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "1.0 1.0\n",
      "1e-08\n",
      "\t0.0001\t22\t97.41\t0.035677\t2.56\t0.983031159538502\n",
      "\n",
      "\n",
      "1e-06\n",
      "\t0.001\t9\t134.75\t0.035671\t2.35\t0.9830312515634204\n",
      "\n",
      "\n",
      "0.0001\n",
      "\t0.01\t5\t106.39\t0.035755\t2.06\t0.9830358914472521\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eps_list = [1e-8, 1e-6, 1e-4]\n",
    "\n",
    "n = 1\n",
    "n_list = [3, 5, 7]\n",
    "\n",
    "res = {n:{\"delta\":[], \n",
    "           \"iters_adaptL\":[], \"time_adaptL\":[], \"adaptL,x0-x*\": [], \"normg_adaptL\": [],\n",
    "           \"iters_exact\":[], \"time_exact\":[], \"exact,x0-x*\": [], \"normg_exact\": [],\n",
    "          \"residual_adaptL\":[],\n",
    "          \"iters_adaptLdelta\":[], \"time_adaptLdelta\":[], \"adaptLdelta,x0-x*\": [], \"normg_adaptLdelta\": []} for n in n_list}\n",
    "mu_list = {}\n",
    "number = 10\n",
    "save_iter = 1\n",
    "N = 900000\n",
    "methods = []\n",
    "np.random.seed(1)\n",
    "print(2)\n",
    "for n in n_list:\n",
    "    print(n)\n",
    "    gradf, f = get_params(n)\n",
    "    w = np.ones(n)\n",
    "    w[0] *= -1\n",
    "    print(np.linalg.norm(gradf(w)), f(w))\n",
    "    for eps in eps_list:\n",
    "        mu = 1e-6\n",
    "        Delta = np.sqrt(eps)\n",
    "        f_inexact = lambda x: f(x) + eps * np.random.uniform(-1, 1)\n",
    "        res[n][\"delta\"].append(int(np.log10(Delta)))\n",
    "        tol = 2*Delta\n",
    "\n",
    "\n",
    "        grad_inexact = lambda w: gradf_inexact(w, gradf, Delta, 3)\n",
    "        print(eps)\n",
    "        method = GradientDescent(AdaptiveL(L0=1, Delta=Delta, Lmin=mu/4, delta=eps), name=\"GD, Delta={}\".format(Delta), save_iter=save_iter)\n",
    "        x = method.solve(w, f_inexact, grad_inexact, tol=tol, max_iter=N)\n",
    "        g = lambda: GradientDescent(AdaptiveL(L0=1, Delta=Delta, Lmin=mu/4),\n",
    "                                    return_history=False).solve(w, f_inexact, grad_inexact, tol=tol, max_iter=N)\n",
    "        if len(method.history) > 1000:\n",
    "            number = 1\n",
    "        else:\n",
    "            number = 10\n",
    "        T = timeit.timeit(g, number=number)/number        \n",
    "        print(\"\\t{}\\t{}\\t{:.2f}\\t{:.6f}\\t{:.2f}\\t{}\".format(Delta, len(method.history), T, np.linalg.norm(x-w), \n",
    "                                                np.linalg.norm(gradf(x))/Delta, f(x)))\n",
    "        methods.append(method)\n",
    "        res[n][\"iters_adaptL\"].append(len(method.history))\n",
    "        res[n][\"time_adaptL\"].append(\"{:.2f}\".format(T))\n",
    "        res[n][\"adaptL,x0-x*\"].append(\"{:.3f}\".format(np.linalg.norm(x-w)))\n",
    "        res[n][\"normg_adaptL\"].append(\"{:.2f}\".format(np.linalg.norm(gradf(x))/Delta))\n",
    "        res[n][\"residual_adaptL\"].append(f(x))\n",
    "        print(\"\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 & \\begin{tabular}{@{}c@{}} $10^{-4}$ \\\\ $10^{-3}$ \\\\ $10^{-2}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $13703$ \\\\ $2531$ \\\\ $498$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $247.73$ \\\\ $258.80$ \\\\ $394.30$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $1.997$ \\\\ $2.163$ \\\\ $2.752$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.99$ \\\\ $2.99$ \\\\ $2.97$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.22 \\cdot 10^{-4}$ \\\\ $0.12 \\cdot 10^{-2}$ \\\\ $0.13 \\cdot 10^{-1}$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "5 & \\begin{tabular}{@{}c@{}} $10^{-4}$ \\\\ $10^{-3}$ \\\\ $10^{-2}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $55452$ \\\\ $15295$ \\\\ $5$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $303.51$ \\\\ $298.79$ \\\\ $60.15$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.893$ \\\\ $3.339$ \\\\ $0.036$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $3.00$ \\\\ $2.80$ \\\\ $2.06$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.36 \\cdot 10^{-3}$ \\\\ $0.51 \\cdot 10^{-2}$ \\\\ $0.98$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "7 & \\begin{tabular}{@{}c@{}} $10^{-4}$ \\\\ $10^{-3}$ \\\\ $10^{-2}$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $22$ \\\\ $9$ \\\\ $5$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $97.41$ \\\\ $134.75$ \\\\ $106.39$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.036$ \\\\ $0.036$ \\\\ $0.036$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $2.56$ \\\\ $2.35$ \\\\ $2.06$ \\end{tabular}&\\begin{tabular}{@{}c@{}} $0.98$ \\\\ $0.98$ \\\\ $0.98$ \\end{tabular}\\\\\n",
      "\\hline\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "\n",
    "for d in n_list:\n",
    "    s += str(d) + \" & \"\n",
    "\n",
    "    cur_list = [\"$10^{{{}}}$\".format(i) for i in res[d][\"delta\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "\n",
    "    cur_list = [\"${}$\".format(i) for i in res[d][\"iters_adaptL\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[d][\"time_adaptL\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    \n",
    "    cur_list = [\"${}$\".format(i) for i in res[d][\"adaptL,x0-x*\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    cur_list = [\"${}$\".format(i) for i in res[d][\"normg_adaptL\"]]\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}&\"\n",
    "    \n",
    "    cur_list1 = [(i/10**(int(np.log10(i))), int(np.log10(i))) for i in res[d][\"residual_adaptL\"]]\n",
    "    cur_list = []\n",
    "    for a, b in cur_list1:\n",
    "        if b != 0:\n",
    "            cur_list.append(\"${:.2f} \\\\cdot 10^{{{}}}$\".format(a, b))\n",
    "        else:\n",
    "            cur_list.append(\"${:.2f}$\".format(a))\n",
    "\n",
    "    s+= \"\\\\begin{tabular}{@{}c@{}} \" + \" \\\\\\\\ \".join(cur_list) + \" \\\\end{tabular}\"\n",
    "\n",
    "    s+= \"\\\\\\\\\\n\\\\hline\\n\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
